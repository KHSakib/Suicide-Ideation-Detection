# -*- coding: utf-8 -*-
"""LIWC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pN2Lkpq87ps7nli_5cVdJBD97ya32tFl
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import tensorflow as tf
import pandas as pd
import tensorflow_hub as hub
import matplotlib.pyplot as plt

tf.get_logger().setLevel('ERROR')

df=pd.read_excel('/content/drive/MyDrive/Data set/Book1.xlsx')
df.head()

df.isnull().sum()

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Dropout
from sklearn.model_selection import train_test_split

X = df.drop(['Source (A)', 'Response'], axis = 1)
y = df['Response']

X

X = pd.DataFrame(X)
X

X.shape, y.shape
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
X_train.shape

"""# **RandomForest Model**"""

RANDOM_STATE = 123
from sklearn.ensemble import RandomForestClassifier

#Train random forest classification model
model = RandomForestClassifier(max_depth=150, random_state=RANDOM_STATE)
model.fit(X_train, y_train)

RF = model.score(X_train, y_train)
print('Training Accuracy of RandomForest : ',RF)

RF = model.score(X_test, y_test)
print('Testing Accuracy of RandomForest : ',RF)

# Diagnosis prediction
y_predict1 = model.predict(X_train)

# Probability of malignant tissue produced by the model
y_prob1 = model.predict(X_train)

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score
cm = confusion_matrix(y_train, y_predict1)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predict1),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr1, tpr1, _1 = roc_curve(y_train, y_prob1)
roc_auc1 = auc(fpr1, tpr1)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr1, tpr1, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc1)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

# Diagnosis prediction
y_predict11 = model.predict(X_test)

# Probability of malignant tissue produced by the model
y_prob11 = model.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict11)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predict11),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr11, tpr11, _11 = roc_curve(y_test, y_prob11)
roc_auc11 = auc(fpr11, tpr11)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr11, tpr11, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc11)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

import numpy as np

# Feature importance dataframe
imp_df = pd.DataFrame({'feature': X_train.columns.values,
                       'importance': model.feature_importances_})

# Reorder by importance
ordered_df = imp_df.sort_values(by='importance')
imp_range=range(1,len(imp_df.index)+1)

## Barplot with confidence intervals
height = ordered_df['importance']
bars = ordered_df['feature']
y_pos = np.arange(len(bars))

# Create horizontal bars
plt.barh(y_pos, height)

# Create names on the y-axis
plt.yticks(y_pos, bars)

plt.xlabel("Mean reduction in tree impurity in random forest")

plt.tight_layout()
# Show graphic
plt.show()

#Install non-standard packages
!pip install shap
!pip install lime
!pip install eli5

pip install --user scikit-learn

#eli5 package (https://eli5.readthedocs.io/en/latest)
import eli5
from eli5.sklearn import PermutationImportance

#lime package (https://github.com/marcotcr/lime)
import lime
import lime.lime_tabular

#shap package (https://github.com/slundberg/shap)
import shap

#Explain samples in test set
X_explain = X_test
explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train.values,
                                                   feature_names=X_train.columns.values,
                                                   discretize_continuous=True,
                                                   class_names=["Suicidal", "Non Suicidal"],
                                                   mode="classification",
                                                   verbose=True,
                                                   random_state=RANDOM_STATE)

#Explaining first subject in test set using all 10 features
exp = explainer.explain_instance(X_explain.values[2,:],model.predict_proba,
                                 num_features=10)
#Plot local explanation
plt = exp.as_pyplot_figure()
plt.tight_layout()
exp.show_in_notebook(show_table=True)

# Import the SHAP library
import shap
import matplotlib.pyplot as plt

# load JS visualization code to notebook
shap.initjs()

model = RandomForestClassifier(max_depth=4, random_state=RANDOM_STATE).fit(X_train, y_train)
# Create the explainer
explainer = shap.TreeExplainer(model)

"""
Compute shap_values for all of X_test rather instead of
a single row, to have more data for plot.
"""
shap_values = explainer.shap_values(X_test)

print("Variable Importance Plot - Suicide Ideation Detection")
figure = plt.figure()
shap.summary_plot(shap_values, X_test)

"""# **Support Vector Machine (SVM) Model**"""

from sklearn.svm import SVC
svc_model = SVC()
svc_model.fit(X_train, y_train)

svm = svc_model.score(X_train, y_train)
print('Training Accuracy of SVM : ',svm)

svm = svc_model.score(X_test, y_test)
print('Testing Accuracy of SVM : ',svm)

# Diagnosis prediction
y_predict2 = svc_model.predict(X_train)

# Probability of malignant tissue produced by the model
y_prob2 =  svc_model.predict(X_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_train, y_predict2)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predict2),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr2, tpr2, _2 = roc_curve(y_train, y_prob2)
roc_auc2 = auc(fpr2, tpr2)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr2, tpr2, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc2)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

# Diagnosis prediction
y_predict22 = svc_model.predict(X_test)

# Probability of malignant tissue produced by the model
y_prob22 = svc_model.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict22)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predict22),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr22, tpr22, _22 = roc_curve(y_test, y_prob22)
roc_auc22 = auc(fpr22, tpr22)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr22, tpr22, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc22)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

"""# **GaussianNB Model**"""

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)

gnb = classifier.score(X_train, y_train)
print('Training Accuracy of GaussianNB : ',gnb)

gnb = classifier.score(X_test, y_test)
print('Testing Accuracy of GaussianNB : ',gnb)

# Diagnosis prediction
y_predict3 = classifier.predict(X_train)

# Probability of malignant tissue produced by the model
y_prob3 = classifier.predict(X_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_train, y_predict3)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predict3),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr3, tpr3, _3 = roc_curve(y_train, y_prob3)
roc_auc3 = auc(fpr3, tpr3)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr3, tpr3, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc3)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

# Diagnosis prediction
y_predict33 = classifier.predict(X_test)

# Probability of malignant tissue produced by the model
y_prob33 = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict33)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predict33),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr33, tpr33, _33 = roc_curve(y_test, y_prob33)
roc_auc33 = auc(fpr33, tpr33)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr33, tpr33, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc33)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

"""# **LogisticRegression Model**"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
predt = lr.predict(X_train)
predtt = lr.predict(X_test)

lr = accuracy_score(y_train, predt)
print('Training Accuracy of LogisticRegression : ',lr)

lr = accuracy_score(y_test, predtt)
print('Testing Accuracy of LogisticRegression : ',lr)

# Diagnosis prediction
y_predict4 = predt

# Probability of malignant tissue produced by the model
y_prob4 = predt

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_train, y_predict4)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predict4),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr4, tpr4, _4 = roc_curve(y_train, y_prob4)
roc_auc4 = auc(fpr4, tpr4)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr4, tpr4, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc4)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

# Diagnosis prediction
y_predict44 = predtt

# Probability of malignant tissue produced by the model
y_prob44 = predtt

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict44)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predict44),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr44, tpr44, _44 = roc_curve(y_test, y_prob44)
roc_auc44 = auc(fpr44, tpr44)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr44, tpr44, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc44)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

"""# **KNeighbors Model**"""

from sklearn.neighbors import KNeighborsClassifier
classifier= KNeighborsClassifier(n_neighbors=150, metric='minkowski', p=2 )
classifier.fit(X_train, y_train)

kng = classifier.score(X_train, y_train)
print('Training Accuracy of KNeighbors : ',kng)

kng = classifier.score(X_test, y_test)
print('Testing Accuracy of KNeighbors : ',kng)

# Diagnosis prediction
y_predict5 = classifier.predict(X_train)

# Probability of malignant tissue produced by the model
y_prob5 = classifier.predict(X_train)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_train, y_predict5)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predict5),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr5, tpr5, _5 = roc_curve(y_train, y_prob5)
roc_auc5 = auc(fpr5, tpr5)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr5, tpr5, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc5)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

# Diagnosis prediction
y_predict55 = classifier.predict(X_test)

# Probability of malignant tissue produced by the model
y_prob55 = classifier.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_predict55)

cm

import seaborn as sns
#Plotting the confusion matrix
plt.figure(figsize=(9,9))
sns.heatmap(cm, annot=True, fmt="", linewidths=.5, square = True, cmap = 'Blues_r');
plt.title('Confusion Matrix')
plt.ylabel('Actal Values')
plt.xlabel('Predicted Values')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predict55),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr55, tpr55, _55 = roc_curve(y_test, y_prob55)
roc_auc55 = auc(fpr55, tpr55)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr55, tpr55, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc55)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("Suicide Ideation Detection")
plt.legend(loc="lower right")
plt.show()

"""# **AUC Curve for All Models (Training)**"""

# matplotlib
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr1, tpr1, linestyle='--',color='orange', label = 'Random Forest (AUC = %0.2f)' % roc_auc1)
plt.plot(fpr2, tpr2, linestyle='--',color='red', label = 'SVM (AUC = %0.2f)' % roc_auc2)
plt.plot(fpr3, tpr3, linestyle='--',color='blue', label = 'GaussianNB (AUC = %0.2f)' % roc_auc3)
plt.plot(fpr4, tpr4, linestyle='--',color='green', label = 'LogisticRegression (AUC = %0.2f)' % roc_auc4)
plt.plot(fpr5, tpr5, linestyle='--',color='yellow', label = 'KNeighbors (AUC = %0.2f)' % roc_auc5)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')

plt.axis([0,100,0,100])

# x label
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower right")
plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();

"""# **AUC Curve for All Models (Testing)**"""

# matplotlib
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr11, tpr11, linestyle='--',color='orange', label = 'Random Forest (AUC = %0.2f)' % roc_auc11)
plt.plot(fpr22, tpr22, linestyle='--',color='red', label = 'SVM (AUC = %0.2f)' % roc_auc22)
plt.plot(fpr33, tpr33, linestyle='--',color='blue', label = 'GaussianNB (AUC = %0.2f)' % roc_auc33)
plt.plot(fpr44, tpr44, linestyle='--',color='green', label = 'LogisticRegression (AUC = %0.2f)' % roc_auc44)
plt.plot(fpr55, tpr55, linestyle='--',color='yellow', label = 'KNeighbors (AUC = %0.2f)' % roc_auc55)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')

plt.axis([0,100,0,100])

# x label
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower right")
plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();