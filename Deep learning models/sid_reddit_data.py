# -*- coding: utf-8 -*-
"""SID_Reddit_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18-ijWatgMtxbiSsopySVJEruxXDA6DLF
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd

df=pd.read_csv('/content/drive/MyDrive/Data set/Reddit_Data(TF-IDF-24K).csv')
df.head()

from sklearn.model_selection import train_test_split

# A dependency of the preprocessing for BERT inputs
!pip install -q -U "tensorflow-text==2.8.*"

!pip install -q tf-models-official==2.7.0

import os
import shutil

import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text as text
from official.nlp import optimization  # to create AdamW optimizer

import matplotlib.pyplot as plt

tf.get_logger().setLevel('ERROR')

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Dropout
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MultiLabelBinarizer

###Drop Nan Values
df=df.dropna()

## Get the Independent Features

X=df.drop('category',axis=1)

## Get the Dependent features
y=df['category']

y.value_counts()

X.shape, y.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train.head(4)

"""# **BERT Model Implementation**"""

bert_preprocess = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
bert_encoder = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")

# Bert layers
text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
preprocessed_text = bert_preprocess(text_input)
outputs = bert_encoder(preprocessed_text)
# Neural network layers
l = tf.keras.layers.Dropout(0.1, name="dropout")(outputs['pooled_output'])
l = tf.keras.layers.Dense(1, activation='sigmoid', name="output")(l)
# Use inputs and outputs to construct a final model
model = tf.keras.Model(inputs=[text_input], outputs = [l])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=10, batch_size = 32)

bert = model.evaluate(X_train, y_train)

print( 'Loss = {} %'.format( bert[0]))
print( 'Accuracy = {} %'.format( bert[1] * 100))

bert = model.evaluate(X_test, y_test)

print( 'Loss = {} %'.format( bert[0]))
print( 'Accuracy = {} %'.format( bert[1] * 100))

y_predicted1 = model.predict(X_train)
y_predicted1 = y_predicted1.flatten()

print(y_predicted1)

y_predicted1 = np.where(y_predicted1 > 0.5, 1, 0)
y_predicted1

from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_train, y_predicted1)
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import itertools

model.fit(X_train, y_train)

y_prob1 = [probs[0] for probs in model.predict(X_train)]

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predicted1),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr1, tpr1, _1 = roc_curve(y_train, y_prob1)
roc_auc1 = auc(fpr1, tpr1)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr1, tpr1, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc1)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for BERT Model (Training)")
plt.legend(loc="lower right")
plt.show()

y_predicted11 = model.predict(X_test)
y_predicted11 = y_predicted11.flatten()

print(y_predicted11)

y_predicted11 = np.where(y_predicted11 > 0.5, 1, 0)
y_predicted11

cm = confusion_matrix(y_test, y_predicted11)
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123
import matplotlib.pyplot as plt
import itertools

model.fit(X_train, y_train)

y_prob11 = [probs[0] for probs in model.predict(X_test)]

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predicted11),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr11, tpr11, _11 = roc_curve(y_test, y_prob11)
roc_auc11 = auc(fpr11, tpr11)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr11, tpr11, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc11)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for BERT Model (Testing)")
plt.legend(loc="lower right")
plt.show()

"""# **LSTM Model Implementation**"""

### Vocabulary size
voc_size=5000

messages=X.copy()

messages['tweet'][1]

messages.reset_index(inplace=True)

import nltk
import re
from nltk.corpus import stopwords

nltk.download('stopwords')

### Dataset Preprocessing
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
corpus = []
for i in range(0, len(messages)):
    print(i)
    review = re.sub('[^a-zA-Z]', ' ', messages['tweet'][i])
    review = review.lower()
    review = review.split()

    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]
    review = ' '.join(review)
    corpus.append(review)

corpus

onehot_repr=[one_hot(words,voc_size)for words in corpus]
onehot_repr

sent_length=20
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)

embedded_docs[0]

import numpy as np
X_final=np.array(embedded_docs)
y_final=np.array(y)

X_final.shape,y_final.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)

## Creating model
embedding_vector_features=40
model=Sequential()
model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))
model.add(LSTM(100))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(model.summary())

### Finally Training
lstm = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=32)

lstm = model.evaluate(X_train, y_train)

print( 'Loss = {} %'.format( lstm[0]))
print( 'Accuracy = {} %'.format( lstm[1] * 100))

lstm = model.evaluate(X_test, y_test)

print( 'Loss = {} %'.format( lstm[0]))
print( 'Accuracy = {} %'.format( lstm[1] * 100))

y_predicted2 = model.predict(X_train)
y_predicted2 = y_predicted2.flatten()

y_predicted2 = np.where(y_predicted2 > 0.5, 1, 0)
y_predicted2

cm = confusion_matrix(y_train, y_predicted2)
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123
import itertools

model.fit(X_train, y_train)

y_prob2 = [probs[0] for probs in model.predict(X_train)]

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predicted2),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr2, tpr2, _2 = roc_curve(y_train, y_prob2)
roc_auc2 = auc(fpr2, tpr2)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr2, tpr2, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc2)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for LSTM Model (Training)")
plt.legend(loc="lower right")
plt.show()

y_predicted22 = model.predict(X_test)
y_predicted22 = y_predicted22.flatten()

y_predicted22 = np.where(y_predicted22 > 0.5, 1, 0)
y_predicted22

cm = confusion_matrix(y_test, y_predicted22)
cm

import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123

model.fit(X_test, y_test)

y_prob22 = [probs[0] for probs in model.predict(X_test)]

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predicted22),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr22, tpr22, _22 = roc_curve(y_test, y_prob22)
roc_auc22 = auc(fpr22, tpr22)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr22, tpr22, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc22)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for LSTM Model (Testing)")
plt.legend(loc="lower right")
plt.show()

"""# **BiLSTM Model Implementation**"""

## Creating model
embedding_vector_features=40
model1=Sequential()
model1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))
model1.add(Bidirectional(LSTM(100)))
model1.add(Dropout(0.3))
model1.add(Dense(1,activation='sigmoid'))
model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(model1.summary())

### Finally Training
model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=32)

Bilstm = model1.evaluate(X_train, y_train)

print( 'Loss = {} %'.format( Bilstm[0]))
print( 'Accuracy = {} %'.format( Bilstm[1] * 100))

Bilstm = model1.evaluate(X_test, y_test)

print( 'Loss = {} %'.format( Bilstm[0]))
print( 'Accuracy = {} %'.format( Bilstm[1] * 100))

y_predicted3 = model1.predict(X_train)
y_predicted3 = y_predicted3.flatten()

y_predicted3 = np.where(y_predicted3 > 0.5, 1, 0)
y_predicted3

cm = confusion_matrix(y_train, y_predicted3)
cm

from matplotlib import pyplot as plt
import seaborn as sn
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123

#Train random forest classification model
#model = RandomForestClassifier(max_depth=4, random_state=RANDOM_STATE)
model1.fit(X_train, y_train)

y_prob3 = [probs[0] for probs in model1.predict(X_train)]

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_train, y_predicted3),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr3, tpr3, _3 = roc_curve(y_train, y_prob3)
roc_auc3 = auc(fpr3, tpr3)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr3, tpr3, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc3)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for BiLSTM Model (Training)")
plt.legend(loc="lower right")
plt.show()

y_predicted33 = model1.predict(X_test)
y_predicted33 = y_predicted33.flatten()

y_predicted33 = np.where(y_predicted33 > 0.5, 1, 0)
y_predicted33

cm = confusion_matrix(y_test, y_predicted33)
cm

sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

Sensitivity = cm[0][0]/(cm[0][0]+cm[1][0])
Specificity = cm[1][1]/(cm[1][1]+cm[0][1])
Precision = cm[0][0]/(cm[0][0]+cm[0][1])
Recall = cm[0][0]/(cm[0][0]+cm[1][0])

print( 'Specificity = {} %'.format(Specificity*100))
print( 'Sensitivity = {} %'.format(Sensitivity*100))
print( 'Precision = {} %'.format(Precision*100))
print( 'Recall = {} %'.format(Recall*100))

RANDOM_STATE = 123

#Train random forest classification model
#model = RandomForestClassifier(max_depth=4, random_state=RANDOM_STATE)
model1.fit(X_train, y_train)

y_prob33 = [probs[0] for probs in model1.predict(X_test)]

# Confusion matrix test set
pd.DataFrame(
    confusion_matrix(y_test, y_predicted33),
    columns=['Predicted Benign', 'Predicted Malignant'],
    index=['Benign', 'Malignant']
)

# Compute area under the curve
fpr33, tpr33, _33 = roc_curve(y_test, y_prob33)
roc_auc33 = auc(fpr33, tpr33)

#Set default figure size
plt.rcParams['figure.figsize'] = (8,8)

# Plot ROC curve
plt.figure()
lw = 2
plt.plot(fpr33, tpr33, color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc33)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("AUC Curve for BiLSTM Model (Testing)")
plt.legend(loc="lower right")
plt.show()

"""# **AUC Curve for All Models (Training)**"""

# matplotlib
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr1, tpr1, linestyle='--',color='orange', label = 'BERT (AUC = %0.2f)' % roc_auc1)
plt.plot(fpr2, tpr2, linestyle='--',color='red', label = 'LSTM (AUC = %0.2f)' % roc_auc2)
plt.plot(fpr3, tpr3, linestyle='--',color='blue', label = 'BiLSTM (AUC = %0.2f)' % roc_auc3)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')

plt.axis([0,100,0,100])

# x label
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower right")
plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();

"""# **AUC Curve for All Models (Testing)**"""

# matplotlib
import matplotlib.pyplot as plt
plt.style.use('seaborn')

# plot roc curves
plt.plot(fpr11, tpr11, linestyle='--',color='orange', label = 'BERT (AUC = %0.2f)' % roc_auc11)
plt.plot(fpr22, tpr22, linestyle='--',color='red', label = 'LSTM (AUC = %0.2f)' % roc_auc22)
plt.plot(fpr33, tpr33, linestyle='--',color='blue', label = 'BiLSTM (AUC = %0.2f)' % roc_auc33)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')

plt.axis([0,100,0,100])

# x label
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.legend(loc="lower right")
plt.legend(loc='best')
plt.savefig('ROC',dpi=300)
plt.show();

"""# **Explainability**"""

#Install non-standard packages
!pip install shap
!pip install lime
!pip install eli5

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split

tfidf = TfidfVectorizer(analyzer = 'word', max_features = 100)
X = tfidf.fit_transform(df['clean_comment'])
X

y = df['category']
X = X.toarray()
X

X = pd.DataFrame(X)
X

feature = tfidf.vocabulary_
col_names = []

for key, value in feature.items():
    print(key, ' : ', value)
    col_names.append(key)

X.columns = col_names
col_names
X

X.shape, y.shape
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
X_train.shape

pip install --user scikit-learn

#eli5 package (https://eli5.readthedocs.io/en/latest)
import eli5
from eli5.sklearn import PermutationImportance

#lime package (https://github.com/marcotcr/lime)
import lime
import lime.lime_tabular

#shap package (https://github.com/slundberg/shap)
import shap

RANDOM_STATE = 123
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import itertools

#Train random forest classification model
model = RandomForestClassifier(max_depth=4, random_state=RANDOM_STATE)
model.fit(X_train, y_train)

# Diagnosis prediction
y_predict = model.predict(X_test)

# Probability of malignant tissue produced by the model
y_prob = [probs[1] for probs in model.predict_proba(X_test)]

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(max_depth=4, random_state=123)
model.fit(X_train, y_train)

# Feature importance dataframe
imp_df = pd.DataFrame({'feature': X_train.columns.values,
                       'importance': model.feature_importances_})

# Reorder by importance
ordered_df = imp_df.sort_values(by='importance')
imp_range=range(1,len(imp_df.index)+1)

## Barplot with confidence intervals
height = ordered_df['importance']
bars = ordered_df['feature']
y_pos = np.arange(len(bars))

# Create horizontal bars
plt.barh(y_pos, height)

# Create names on the y-axis
plt.yticks(y_pos, bars)

plt.xlabel("Mean reduction in tree impurity in random forest")

plt.tight_layout()
# Show graphic
plt.show()

"""# **LIME**"""

#Explain samples in test set
X_explain = X_test
explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train.values,
                                                   feature_names=X_train.columns.values,
                                                   discretize_continuous=True,
                                                   class_names=["Suicidal", "Non Suicidal"],
                                                   mode="classification",
                                                   verbose=True,
                                                   random_state=RANDOM_STATE)

#Explaining first subject in test set using all 10 features
exp = explainer.explain_instance(X_explain.values[5,:],model.predict_proba,
                                 num_features=10)
#Plot local explanation
plt = exp.as_pyplot_figure()
plt.tight_layout()
exp.show_in_notebook(show_table=True)

"""# **SHAP**"""

# explain the model's predictions on test set using SHAP values
# same syntax works for xgboost, LightGBM, CatBoost, and some scikit-learn models
explainer = shap.TreeExplainer(model)

# shap_values consists of a list of two matrices of dimension samplesize x #features
# The first matrix uses average nr of benign samples as base value
# The second matrix which is used below uses average nr of malignant samples as base value
shap_values = explainer.shap_values(X_explain)


# Interactive visualization of the explanation of the first subject
# in the test set (X_explain).
# It shows the relative contribution of features to get from the base value of malignant
# samples(average value)
# to the output value (1 in case of malignant sample)
# the numbers at the bottom show the actual values for this sample.
shap.initjs() #initialize javascript in cell
shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_explain.iloc[0,:])

# Import the SHAP library
import shap
import matplotlib.pyplot as plt

# load JS visualization code to notebook
shap.initjs()

# Create the explainer
explainer = shap.TreeExplainer(model)

"""
Compute shap_values for all of X_test rather instead of
a single row, to have more data for plot.
"""
shap_values = explainer.shap_values(X_test)

print("Variable Importance Plot - Suicide Ideation Detection")
figure = plt.figure()
shap.summary_plot(shap_values, X_test)

#Interactive visualization of all sample/feature Shapley values
#It is possible to show the relative contribution of individual features for all
# samples on the y-axis as well.
shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1], X_explain)

# Dependence Plot on Age feature
shap.dependence_plot('my', shap_values[1], X_test, interaction_index="my")

#A summary plot with the shapley value (feature importance)
shap.summary_plot(shap_values[1], X_explain)

#Same as above, but with violin plots to better see the distribution of shapley values
shap.summary_plot(shap_values[1], X_explain, plot_type="violin")